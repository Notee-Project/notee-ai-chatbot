"""
ë²¡í„°ì €ì¥ì†Œ ì „ìš© íŒŒì´í”„ë¼ì¸ í†µí•© í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

ğŸ“‹ ìš©ë„:
- ë¬¸ì„œ ì²˜ë¦¬ â†’ ë²¡í„° ì €ì¥ì†Œ ìƒì„± â†’ ê²€ìƒ‰ ê¸°ëŠ¥ì˜ ì „ì²´ íë¦„ ê²€ì¦
- ê° ë‹¨ê³„ë³„ ì˜¤ë¥˜ ì§„ë‹¨ ë° ì„±ëŠ¥ í™•ì¸
- ìƒˆë¡œìš´ í™˜ê²½ì—ì„œ ì‹œìŠ¤í…œ ì •ìƒ ì‘ë™ ì—¬ë¶€ í™•ì¸
- ì½”ë“œ ë³€ê²½ í›„ ì „ì²´ ì‹œìŠ¤í…œ ë¬´ê²°ì„± ê²€ì¦

ğŸ¯ ê²€ì¦ ë‹¨ê³„:
1. ë°ì´í„° ìƒíƒœ í™•ì¸ (íŒŒì¼ ì¡´ì¬, í¬ê¸°, êµ¬ì¡°)
2. ë¬¸ì„œ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ (ë¡œë“œ â†’ ë©”íƒ€ë°ì´í„° â†’ ì²­í¬ ë¶„í• )
3. ë²¡í„° ì €ì¥ì†Œ ìƒì„± (ì„ë² ë”© â†’ Chroma DB ì €ì¥)
4. ê²€ìƒ‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ (ìœ ì‚¬ë„ ê²€ìƒ‰ â†’ ê²°ê³¼ ë°˜í™˜)

ğŸš€ ì‹¤í–‰ ì‹œê¸°:
- ê°œë°œ í™˜ê²½ ìµœì´ˆ ì„¤ì • ì‹œ
- ì½”ë“œ ë³€ê²½ í›„ íšŒê·€ í…ŒìŠ¤íŠ¸
- ìƒˆë¡œìš´ ë°ì´í„° ì¶”ê°€ í›„ ê²€ì¦
- ë²„ê·¸ ë¦¬í¬íŠ¸ ì‹œ ë¬¸ì œ ì§€ì  íŒŒì•…

ğŸ“Š ì„±ê³µ ê¸°ì¤€:
- 5ê°œ ë¬¸ì„œ ì²˜ë¦¬ ì™„ë£Œ
- 5ê°œ ì²­í¬ ìƒì„± ì„±ê³µ
- ë²¡í„° ì €ì¥ì†Œ ìƒì„± ë° ê²€ìƒ‰ ê°€ëŠ¥
"""

import os
import sys
import shutil
from typing import List

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# ìˆ˜ì •ëœ ì„í¬íŠ¸
from document_processing import DocumentProcessor
from vector_store import SafeVectorStoreManager as VectorStoreManager

def check_data_directory():
    """ë°ì´í„° ë””ë ‰í† ë¦¬ì™€ íŒŒì¼ ìƒíƒœ í™•ì¸"""
    print("=== ë°ì´í„° ë””ë ‰í† ë¦¬ ìƒíƒœ í™•ì¸ ===")
    
    data_dir = "../data/raw"
    print(f"ë°ì´í„° ë””ë ‰í† ë¦¬: {data_dir}")
    print(f"ë””ë ‰í† ë¦¬ ì¡´ì¬ ì—¬ë¶€: {os.path.exists(data_dir)}")
    
    if os.path.exists(data_dir):
        files = os.listdir(data_dir)
        print(f"ë””ë ‰í† ë¦¬ ë‚´ íŒŒì¼ë“¤: {files}")
        
        # .txt íŒŒì¼ë§Œ í•„í„°ë§
        txt_files = [f for f in files if f.endswith('.txt')]
        print(f"í…ìŠ¤íŠ¸ íŒŒì¼ë“¤: {txt_files}")
        
        # ê° íŒŒì¼ í¬ê¸° í™•ì¸
        for txt_file in txt_files:
            file_path = os.path.join(data_dir, txt_file)
            if os.path.exists(file_path):
                size = os.path.getsize(file_path)
                print(f"  - {txt_file}: {size} bytes")
                
                # íŒŒì¼ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read(200)
                        print(f"    ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {content[:100]}...")
                except Exception as e:
                    print(f"    íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
        
        # metadata.json í™•ì¸
        metadata_path = os.path.join(data_dir, "metadata.json")
        if os.path.exists(metadata_path):
            print("âœ… metadata.json íŒŒì¼ ì¡´ì¬")
            try:
                import json
                with open(metadata_path, 'r', encoding='utf-8') as f:
                    metadata = json.load(f)
                    print(f"ë©”íƒ€ë°ì´í„° ë¬¸ì„œ ìˆ˜: {len(metadata.get('documents', []))}")
            except Exception as e:
                print(f"ë©”íƒ€ë°ì´í„° ì½ê¸° ì˜¤ë¥˜: {e}")
        else:
            print("âŒ metadata.json íŒŒì¼ ì—†ìŒ")
    else:
        print("âŒ ë°ì´í„° ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!")

def test_document_processing():
    """ë¬¸ì„œ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
    print("\n=== ë¬¸ì„œ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ===")
    
    try:
        processor = DocumentProcessor(data_directory="../data/raw")
        
        # 1. ë©”íƒ€ë°ì´í„° ë¡œë“œ í…ŒìŠ¤íŠ¸
        print("1. ë©”íƒ€ë°ì´í„° ë¡œë“œ í…ŒìŠ¤íŠ¸...")
        metadata = processor.load_metadata()
        print(f"ë©”íƒ€ë°ì´í„° ë¡œë“œ ê²°ê³¼: {len(metadata.get('documents', []))}ê°œ ë¬¸ì„œ")
        
        # 2. ë¬¸ì„œ ë¡œë“œ í…ŒìŠ¤íŠ¸
        print("2. ë¬¸ì„œ ë¡œë“œ í…ŒìŠ¤íŠ¸...")
        documents = processor.load_documents()
        print(f"ë¡œë“œëœ ë¬¸ì„œ ìˆ˜: {len(documents)}")
        
        if documents:
            print("ì²« ë²ˆì§¸ ë¬¸ì„œ ì •ë³´:")
            doc = documents[0]
            print(f"  - ì†ŒìŠ¤: {doc.metadata.get('source', 'N/A')}")
            print(f"  - ë‚´ìš© ê¸¸ì´: {len(doc.page_content)} ê¸€ì")
            print(f"  - ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {doc.page_content[:100]}...")
        
        # 3. ì „ì²´ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
        print("3. ì „ì²´ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸...")
        chunks = processor.process_documents()
        print(f"ìƒì„±ëœ ì²­í¬ ìˆ˜: {len(chunks)}")
        
        if chunks:
            print("ì²« ë²ˆì§¸ ì²­í¬ ì •ë³´:")
            chunk = chunks[0]
            print(f"  - ì œëª©: {chunk.metadata.get('title', 'N/A')}")
            print(f"  - ì¹´í…Œê³ ë¦¬: {chunk.metadata.get('category', 'N/A')}")
            print(f"  - ì²­í¬ í¬ê¸°: {len(chunk.page_content)} ê¸€ì")
            print(f"  - ë©”íƒ€ë°ì´í„°: {chunk.metadata}")
        
        return chunks
        
    except Exception as e:
        print(f"ë¬¸ì„œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return []

def clean_vector_store():
    """ê¸°ì¡´ ë²¡í„° ì €ì¥ì†Œ ì™„ì „ ì‚­ì œ"""
    print("\n=== ë²¡í„° ì €ì¥ì†Œ ì´ˆê¸°í™” ===")
    
    vector_db_path = "../data/vector_db"
    if os.path.exists(vector_db_path):
        try:
            shutil.rmtree(vector_db_path)
            print(f"âœ… ê¸°ì¡´ ë²¡í„° ì €ì¥ì†Œ ì‚­ì œ: {vector_db_path}")
        except Exception as e:
            print(f"âŒ ë²¡í„° ì €ì¥ì†Œ ì‚­ì œ ì‹¤íŒ¨: {e}")
    
    # ìƒˆë¡œ ìƒì„±
    os.makedirs(vector_db_path, exist_ok=True)
    print(f"âœ… ìƒˆ ë²¡í„° ì €ì¥ì†Œ ë””ë ‰í† ë¦¬ ìƒì„±: {vector_db_path}")

def test_vector_store_creation(chunks):
    """ë²¡í„° ì €ì¥ì†Œ ìƒì„± í…ŒìŠ¤íŠ¸"""
    print("\n=== ë²¡í„° ì €ì¥ì†Œ ìƒì„± í…ŒìŠ¤íŠ¸ ===")
    
    if not chunks:
        print("âŒ ì²˜ë¦¬ëœ ì²­í¬ê°€ ì—†ì–´ ë²¡í„° ì €ì¥ì†Œë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    try:
        # ë²¡í„° ì €ì¥ì†Œ ê´€ë¦¬ì ì´ˆê¸°í™”
        vector_manager = VectorStoreManager(
            embedding_model="korean",
            vector_db_type="chroma",
            persist_directory="../data/vector_db"
        )
        
        print(f"ì²­í¬ ìˆ˜: {len(chunks)}")
        print("ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì¤‘...")
        
        # ë²¡í„° ì €ì¥ì†Œ ìƒì„±
        vector_manager.create_vector_store_safe(chunks)
        
        # ìƒì„± í™•ì¸
        if vector_manager.vector_store is not None:
            print("âœ… ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì„±ê³µ!")
            
            # ë¬¸ì„œ ê°œìˆ˜ í™•ì¸
            try:
                count = vector_manager.vector_store._collection.count()
                print(f"ğŸ“Š ì €ì¥ëœ ë¬¸ì„œ ê°œìˆ˜: {count}")
            except Exception as e:
                print(f"ë¬¸ì„œ ê°œìˆ˜ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
            
            return vector_manager
        else:
            print("âŒ ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì‹¤íŒ¨")
            return None
            
    except Exception as e:
        print(f"ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return None

def test_search(vector_manager):
    """ê²€ìƒ‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("\n=== ê²€ìƒ‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ===")
    
    if not vector_manager or not vector_manager.vector_store:
        print("âŒ ë²¡í„° ì €ì¥ì†Œê°€ ì—†ì–´ ê²€ìƒ‰ì„ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    test_queries = [
        "ì¥í•™ê¸ˆ",
        "ë„ì„œê´€",
        "í•™ì‹",
        "ìˆ˜ê°•ì‹ ì²­",
        "ê¸°ìˆ™ì‚¬"
    ]
    
    for query in test_queries:
        print(f"\nğŸ” '{query}' ê²€ìƒ‰ ê²°ê³¼:")
        try:
            results = vector_manager.similarity_search_with_score(query, k=2)
            
            if results:
                for i, (doc, score) in enumerate(results, 1):
                    print(f"  {i}. [ì ìˆ˜: {score:.4f}]")
                    print(f"     ì œëª©: {doc.metadata.get('title', 'N/A')}")
                    print(f"     ì¹´í…Œê³ ë¦¬: {doc.metadata.get('category', 'N/A')}")
                    print(f"     ë‚´ìš©: {doc.page_content[:100]}...")
            else:
                print("  ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
                
        except Exception as e:
            print(f"  ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")

def create_sample_data():
    """ìƒ˜í”Œ ë°ì´í„° ìƒì„± (ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°)"""
    print("\n=== ìƒ˜í”Œ ë°ì´í„° ìƒì„± ===")
    
    data_dir = "../data/raw"
    os.makedirs(data_dir, exist_ok=True)
    
    # ìƒ˜í”Œ í…ìŠ¤íŠ¸ íŒŒì¼ë“¤ ìƒì„±
    sample_files = {
        "document_01_í•™ì‚¬.txt": """
í•™ì‚¬ ê´€ë¦¬ ì•ˆë‚´

â–  ìˆ˜ê°•ì‹ ì²­ ì•ˆë‚´
- ìˆ˜ê°•ì‹ ì²­ ê¸°ê°„: 2025ë…„ 2ì›” 10ì¼ ~ 2ì›” 20ì¼
- ì‹ ì²­ ë°©ë²•: í•™ì‚¬ì •ë³´ì‹œìŠ¤í…œ ì ‘ì† í›„ ìˆ˜ê°•ì‹ ì²­ ë©”ë‰´ ì´ìš©
- ë¬¸ì˜ì²˜: í•™ì‚¬íŒ€ (031-123-4567)

â–  ì¥í•™ê¸ˆ ì‹ ì²­ ì•ˆë‚´
- ì„±ì ìš°ìˆ˜ì¥í•™ê¸ˆ: ì§ì „í•™ê¸° í‰ì  3.5 ì´ìƒ
- ì‹ ì²­ ê¸°ê°„: ë§¤í•™ê¸° ê°œê°• í›„ 2ì£¼ ì´ë‚´
- ì œì¶œ ì„œë¥˜: ì¥í•™ê¸ˆì‹ ì²­ì„œ, ì„±ì ì¦ëª…ì„œ
- ë¬¸ì˜ì²˜: í•™ìƒì§€ì›íŒ€ (031-123-4568)

â–  í•™ì  ì¸ì • ë° í¸ì…í•™ ì•ˆë‚´
- í¸ì…í•™ ì‹ ì²­ ìê²©: ì „ë¬¸ëŒ€í•™ ì¡¸ì—…ì ë˜ëŠ” 4ë…„ì œ ëŒ€í•™ 2í•™ë…„ ìˆ˜ë£Œì
- í•™ì  ì¸ì •: ë™ì¼ ê³„ì—´ ê³¼ëª©ì— í•œí•´ ìµœëŒ€ 65í•™ì ê¹Œì§€ ì¸ì •
        """,
        
        "document_02_ì‹œì„¤.txt": """
ìº í¼ìŠ¤ ì‹œì„¤ ì´ìš© ì•ˆë‚´

â–  ë„ì„œê´€ ìš´ì˜ ì•ˆë‚´
- ìš´ì˜ì‹œê°„: í‰ì¼ 09:00 ~ 22:00, ì£¼ë§ 09:00 ~ 18:00
- ëŒ€ì¶œ ê¶Œìˆ˜: í•™ë¶€ìƒ 5ê¶Œ, ëŒ€í•™ì›ìƒ 10ê¶Œ
- ëŒ€ì¶œ ê¸°ê°„: í•™ë¶€ìƒ 14ì¼, ëŒ€í•™ì›ìƒ 30ì¼
- ì—°ì¥: 1íšŒ ê°€ëŠ¥ (ë°˜ë‚©ì˜ˆì •ì¼ ì „ì¼ê¹Œì§€)

â–  í•™ìƒì‹ë‹¹ ìš´ì˜ ì•ˆë‚´
- ìš´ì˜ì‹œê°„: 
  * ì¡°ì‹: 08:00 ~ 09:00 (í‰ì¼ë§Œ)
  * ì¤‘ì‹: 11:30 ~ 14:00
  * ì„ì‹: 17:00 ~ 19:00
- ì‹ë¹„: ì¡°ì‹ 3,000ì›, ì¤‘ì‹ 4,000ì›, ì„ì‹ 4,500ì›
- ê²°ì œë°©ë²•: í•™ìƒì¦, í˜„ê¸ˆ, ì¹´ë“œ

â–  ì²´ìœ¡ì‹œì„¤ ì´ìš© ì•ˆë‚´
- ì²´ìœ¡ê´€ ê°œë°©ì‹œê°„: 06:00 ~ 22:00
- í—¬ìŠ¤ì¥: í‰ì¼ 06:00 ~ 22:00, ì£¼ë§ 09:00 ~ 18:00
- ìˆ˜ì˜ì¥: ì›”/ìˆ˜/ê¸ˆ 06:00 ~ 21:00
        """,
        
        "document_03_êµ­ì œêµë¥˜.txt": """
êµ­ì œêµë¥˜ í”„ë¡œê·¸ë¨ ì•ˆë‚´

â–  í•´ì™¸êµí™˜í•™ìƒ í”„ë¡œê·¸ë¨
- ì‹ ì²­ ìê²©: 2í•™ë…„ ì´ìƒ, í‰ì  3.0 ì´ìƒ
- íŒŒê²¬ ëŒ€í•™: ë¯¸êµ­, ì¼ë³¸, ì¤‘êµ­, ìœ ëŸ½ ë“± 30ì—¬ê°œ ëŒ€í•™
- ì‹ ì²­ ê¸°ê°„: ë§¤ë…„ 3ì›”, 9ì›”
- ì§€ì› í˜œíƒ: ë“±ë¡ê¸ˆ ë©´ì œ, í•­ê³µë£Œ ì¼ë¶€ ì§€ì›

â–  í•´ì™¸ì¸í„´ì‹­ í”„ë¡œê·¸ë¨  
- ëŒ€ìƒ: 3í•™ë…„ ì´ìƒ
- ë¶„ì•¼: IT, ê²½ì˜, ì—”ì§€ë‹ˆì–´ë§
- ê¸°ê°„: 6ê°œì›” ~ 1ë…„
- í˜œíƒ: í˜„ì§€ ì²´ì¬ë¹„ ì§€ì›, í•™ì  ì¸ì •

â–  ì–´í•™ì—°ìˆ˜ í”„ë¡œê·¸ë¨
- ê¸°ê°„: í•˜ê³„/ë™ê³„ ë°©í•™ ì¤‘ 4ì£¼
- êµ­ê°€: ë¯¸êµ­, ì˜êµ­, í˜¸ì£¼, í•„ë¦¬í•€
- ì§€ì› ë‚´ìš©: ìˆ˜ì—…ë£Œ, ìˆ™ë°•ë¹„ ì¼ë¶€ ì§€ì›
        """
    }
    
    # íŒŒì¼ ìƒì„±
    for filename, content in sample_files.items():
        file_path = os.path.join(data_dir, filename)
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content.strip())
        print(f"âœ… ìƒì„±: {filename}")
    
    # ë©”íƒ€ë°ì´í„° íŒŒì¼ ìƒì„±
    metadata = {
        "created_at": "2025-04-20",
        "description": "ëŒ€í•™êµ ê³µì§€ì‚¬í•­ ìƒ˜í”Œ ë°ì´í„°",
        "documents": [
            {
                "id": 1,
                "filename": "document_01_í•™ì‚¬.txt",
                "title": "í•™ì‚¬ ê´€ë¦¬ ì•ˆë‚´",
                "category": "í•™ì‚¬",
                "date": "2025-04-01",
                "source": "í•™ì‚¬íŒ€"
            },
            {
                "id": 2,
                "filename": "document_02_ì‹œì„¤.txt", 
                "title": "ìº í¼ìŠ¤ ì‹œì„¤ ì´ìš© ì•ˆë‚´",
                "category": "ì‹œì„¤",
                "date": "2025-04-02",
                "source": "ì‹œì„¤íŒ€"
            },
            {
                "id": 3,
                "filename": "document_03_êµ­ì œêµë¥˜.txt",
                "title": "êµ­ì œêµë¥˜ í”„ë¡œê·¸ë¨ ì•ˆë‚´", 
                "category": "êµ­ì œêµë¥˜",
                "date": "2025-04-03",
                "source": "êµ­ì œêµë¥˜íŒ€"
            }
        ]
    }
    
    import json
    metadata_path = os.path.join(data_dir, "metadata.json")
    with open(metadata_path, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, ensure_ascii=False, indent=2)
    print("âœ… metadata.json ìƒì„± ì™„ë£Œ")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=== ì „ì²´ íŒŒì´í”„ë¼ì¸ ë””ë²„ê·¸ í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
    
    # 1. ë°ì´í„° ë””ë ‰í† ë¦¬ í™•ì¸
    check_data_directory()
    
    # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ìƒ˜í”Œ ë°ì´í„° ìƒì„±
    if not os.path.exists("../data/raw") or len(os.listdir("../data/raw")) < 2:
        print("\në°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤...")
        create_sample_data()
    
    # 2. ë¬¸ì„œ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
    chunks = test_document_processing()
    
    if not chunks:
        print("âŒ ë¬¸ì„œ ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return
    
    # 3. ë²¡í„° ì €ì¥ì†Œ ì´ˆê¸°í™”
    clean_vector_store()
    
    # 4. ë²¡í„° ì €ì¥ì†Œ ìƒì„± í…ŒìŠ¤íŠ¸
    vector_manager = test_vector_store_creation(chunks)
    
    # 5. ê²€ìƒ‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
    test_search(vector_manager)
    
    print("\n=== ì „ì²´ íŒŒì´í”„ë¼ì¸ ë””ë²„ê·¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ ===")

if __name__ == "__main__":
    main()