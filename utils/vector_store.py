# ì•ˆì „í•œ ë²¡í„° ì €ì¥ì†Œ ê´€ë¦¬ í´ë˜ìŠ¤ (Windows íŒŒì¼ ì ê¸ˆ ë¬¸ì œ í•´ê²°)

# ì ìˆ˜ í•´ì„:
# 0.0 ~ 0.8: ë§¤ìš° ìœ ì‚¬ (ê±°ì˜ ì •í™•í•œ ë§¤ì¹˜)
# 0.8 ~ 1.2: ì–´ëŠ ì •ë„ ìœ ì‚¬ (ê´€ë ¨ì„± ìˆìŒ)
# 1.2 ~ 2.0: ì•½ê°„ ìœ ì‚¬ (ë¶€ë¶„ì  ê´€ë ¨ì„±)
# 2.0 ì´ìƒ: ê±°ì˜ ë¬´ê´€í•¨

import os
import sys
import json
import time
import sqlite3
from typing import List, Dict, Any, Optional
from datetime import datetime
from pathlib import Path

from langchain.schema import Document

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •
PROJECT_ROOT = Path(__file__).parent.parent  # utils í´ë”ì˜ ìƒìœ„ í´ë”
sys.path.append(str(PROJECT_ROOT))

# ìµœì‹  íŒ¨í‚¤ì§€ ì„í¬íŠ¸ (Deprecation ê²½ê³  í•´ê²°)
try:
    from langchain_huggingface import HuggingFaceEmbeddings
    print("âœ… langchain-huggingface ì‚¬ìš©")
except ImportError:
    from langchain_community.embeddings import HuggingFaceEmbeddings
    print("âš ï¸ êµ¬ë²„ì „ langchain_community.embeddings ì‚¬ìš© (ì—…ê·¸ë ˆì´ë“œ ê¶Œì¥)")

try:
    from langchain_chroma import Chroma
    print("âœ… langchain-chroma ì‚¬ìš©")
except ImportError:
    from langchain_community.vectorstores import Chroma
    print("âš ï¸ êµ¬ë²„ì „ langchain_community.vectorstores ì‚¬ìš© (ì—…ê·¸ë ˆì´ë“œ ê¶Œì¥)")

from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings

try:
    from .document_processing import DocumentProcessor
except ImportError:
    from document_processing import DocumentProcessor

class SafeVectorStoreManager:
    """
    ì•ˆì „í•œ ë²¡í„° ì €ì¥ì†Œ ê´€ë¦¬ í´ë˜ìŠ¤ (Windows íŒŒì¼ ì ê¸ˆ ë¬¸ì œ í•´ê²°)
    """
    
    def __init__(self, 
                 embedding_model: str = "korean", 
                 vector_db_type: str = "chroma",
                 persist_directory: str = None):
        """
        SafeVectorStoreManager ì´ˆê¸°í™”
        
        Args:
            embedding_model (str): ì‚¬ìš©í•  ì„ë² ë”© ëª¨ë¸ ("korean", "openai", "multilingual")
            vector_db_type (str): ë²¡í„° DB ì¢…ë¥˜ ("chroma", "faiss")
            persist_directory (str): ë²¡í„° DB ì €ì¥ ê²½ë¡œ (Noneì´ë©´ í”„ë¡œì íŠ¸ ë£¨íŠ¸/data/vector_db ì‚¬ìš©)
        """
        self.embedding_model_type = embedding_model
        self.vector_db_type = vector_db_type
        
        # ê²½ë¡œ ì„¤ì •: í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€
        if persist_directory is None:
            self.persist_directory = PROJECT_ROOT / "data" / "vector_db"
        else:
            self.persist_directory = Path(persist_directory)
        
        print(f"ğŸ—‚ï¸ í”„ë¡œì íŠ¸ ë£¨íŠ¸: {PROJECT_ROOT}")
        print(f"ğŸ—‚ï¸ ë²¡í„° DB ê²½ë¡œ: {self.persist_directory}")
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        self.persist_directory.mkdir(parents=True, exist_ok=True)
        
        # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
        self.embeddings = self._setup_embedding_model()
        
        # ë²¡í„° ì €ì¥ì†Œ (ë‚˜ì¤‘ì— ì´ˆê¸°í™”)
        self.vector_store = None
        
    def _setup_embedding_model(self):
        """
        ì„ë² ë”© ëª¨ë¸ì„ ì„¤ì •í•˜ëŠ” í•¨ìˆ˜
        
        Returns:
            ì„ë² ë”© ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤
        """
        print(f"ì„ë² ë”© ëª¨ë¸ ì„¤ì • ì¤‘: {self.embedding_model_type}")
        
        if self.embedding_model_type == "korean":
            # í•œêµ­ì–´ì— ìµœì í™”ëœ ì„ë² ë”© ëª¨ë¸
            embeddings = HuggingFaceEmbeddings(
                model_name="jhgan/ko-sroberta-multitask",  # í•œêµ­ì–´ íŠ¹í™” ëª¨ë¸
                model_kwargs={
                    'device': 'cpu',  # GPU ì‚¬ìš© ì‹œ 'cuda'ë¡œ ë³€ê²½
                    'trust_remote_code': True
                },
                encode_kwargs={
                    'normalize_embeddings': True,  # ë²¡í„° ì •ê·œí™”
                    'batch_size': 32
                }
            )
            print("âœ… í•œêµ­ì–´ íŠ¹í™” ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: ko-sroberta-multitask")
            
        elif self.embedding_model_type == "openai":
            # OpenAI ì„ë² ë”© ëª¨ë¸
            embeddings = OpenAIEmbeddings(
                model="text-embedding-ada-002",
                openai_api_key=os.getenv("OPENAI_API_KEY")
            )
            print("âœ… OpenAI ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: text-embedding-ada-002")
            
        elif self.embedding_model_type == "multilingual":
            # ë‹¤êµ­ì–´ ì§€ì› ì„ë² ë”© ëª¨ë¸
            embeddings = HuggingFaceEmbeddings(
                model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
                model_kwargs={'device': 'cpu'},
                encode_kwargs={'normalize_embeddings': True}
            )
            print("âœ… ë‹¤êµ­ì–´ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: paraphrase-multilingual-MiniLM-L12-v2")
            
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì„ë² ë”© ëª¨ë¸ì…ë‹ˆë‹¤: {self.embedding_model_type}")
            
        return embeddings
    
    def _safe_cleanup_chroma_files(self):
        """
        Chroma íŒŒì¼ë“¤ì„ ì•ˆì „í•˜ê²Œ ì •ë¦¬í•˜ëŠ” í•¨ìˆ˜
        """
        print("ğŸ§¹ Chroma íŒŒì¼ë“¤ ì•ˆì „ ì •ë¦¬ ì¤‘...")
        
        # ì •ë¦¬í•  íŒŒì¼ë“¤
        files_to_clean = [
            self.persist_directory / "chroma.sqlite3",
            self.persist_directory / "chroma.sqlite3-shm",
            self.persist_directory / "chroma.sqlite3-wal"
        ]
        
        # ê° íŒŒì¼ì— ëŒ€í•´ ì•ˆì „í•œ ì‚­ì œ ì‹œë„
        for file_path in files_to_clean:
            if file_path.exists():
                print(f"ğŸ—‘ï¸ íŒŒì¼ ì‚­ì œ ì‹œë„: {file_path}")
                
                # ë°©ë²• 1: SQLite ì—°ê²° ê°•ì œ ì¢…ë£Œ
                if file_path.name == "chroma.sqlite3":
                    try:
                        # SQLite íŒŒì¼ì´ë¼ë©´ ì—°ê²°ì„ ê°•ì œë¡œ ë‹«ê¸°
                        conn = sqlite3.connect(str(file_path))
                        conn.close()
                        time.sleep(0.1)
                    except:
                        pass
                
                # ë°©ë²• 2: íŒŒì¼ ì†ì„± ë³€ê²½ í›„ ì‚­ì œ
                try:
                    file_path.chmod(0o777)
                    time.sleep(0.1)
                    file_path.unlink()
                    print(f"âœ… ì‚­ì œ ì„±ê³µ: {file_path.name}")
                except PermissionError:
                    print(f"âš ï¸ ê¶Œí•œ ì˜¤ë¥˜ë¡œ ì‚­ì œ ì‹¤íŒ¨: {file_path.name}")
                except FileNotFoundError:
                    print(f"â„¹ï¸ íŒŒì¼ì´ ì´ë¯¸ ì—†ìŒ: {file_path.name}")
                except Exception as e:
                    print(f"âš ï¸ ì‚­ì œ ì‹¤íŒ¨: {file_path.name} - {e}")
    
    def _force_close_chroma_connections(self):
        """
        Chroma ê´€ë ¨ ì—°ê²°ë“¤ì„ ê°•ì œë¡œ ë‹«ëŠ” í•¨ìˆ˜
        """
        try:
            # ê¸°ì¡´ vector_storeê°€ ìˆë‹¤ë©´ ì •ë¦¬
            if hasattr(self, 'vector_store') and self.vector_store is not None:
                print("ğŸ”Œ ê¸°ì¡´ ë²¡í„° ì €ì¥ì†Œ ì—°ê²° ì •ë¦¬ ì¤‘...")
                
                # Chroma í´ë¼ì´ì–¸íŠ¸ ì •ë¦¬
                if hasattr(self.vector_store, '_client'):
                    try:
                        self.vector_store._client.reset()
                    except:
                        pass
                
                if hasattr(self.vector_store, '_collection'):
                    try:
                        del self.vector_store._collection
                    except:
                        pass
                
                # ê°ì²´ ì‚­ì œ
                del self.vector_store
                self.vector_store = None
                
                # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ê°•ì œ ì‹¤í–‰
                import gc
                gc.collect()
                time.sleep(1)
                
                print("âœ… ê¸°ì¡´ ì—°ê²° ì •ë¦¬ ì™„ë£Œ")
                
        except Exception as e:
            print(f"âš ï¸ ì—°ê²° ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
    
    def create_vector_store_safe(self, documents: List[Document]) -> None:
        """
        ì•ˆì „í•˜ê²Œ ë²¡í„° ì €ì¥ì†Œë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ (ì™„ì „ ì´ˆê¸°í™” ë°©ì‹)       
        Args:
            documents (List[Document]): ë²¡í„°í™”í•  ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        """
        if not documents:
            print("âŒ ë²¡í„°í™”í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
            
        print(f"ğŸš€ ì•ˆì „í•œ ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì¤‘... (ë¬¸ì„œ ìˆ˜: {len(documents)})")
        print(f"ğŸ“ ì €ì¥ ê²½ë¡œ: {self.persist_directory}")
        
        # ë¬¸ì„œ ë‚´ìš© í™•ì¸
        print("ğŸ“„ ë¬¸ì„œ ìƒ˜í”Œ í™•ì¸:")
        for i, doc in enumerate(documents[:3]):
            print(f"  ë¬¸ì„œ {i+1}: {len(doc.page_content)} ê¸€ì")
            print(f"    ë©”íƒ€ë°ì´í„°: {doc.metadata}")
            print(f"    ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {doc.page_content[:100]}...")
        
        try:
            if self.vector_db_type == "chroma":
                # 1. ê¸°ì¡´ ì—°ê²° ì •ë¦¬
                self._force_close_chroma_connections()
                
                # 2. ì „ì²´ ë²¡í„° DB ë””ë ‰í† ë¦¬ ì™„ì „ ì‚­ì œ
                import shutil
                if self.persist_directory.exists():
                    print(f"ğŸ—‘ï¸ ì „ì²´ ë²¡í„° DB ë””ë ‰í† ë¦¬ ì‚­ì œ ì¤‘: {self.persist_directory}")
                    
                    # Windowsì—ì„œ ê¶Œí•œ ë¬¸ì œ í•´ê²°
                    def remove_readonly(func, path, _):
                        import stat
                        os.chmod(path, stat.S_IWRITE)
                        func(path)
                    
                    try:
                        shutil.rmtree(str(self.persist_directory), onerror=remove_readonly)
                        print("âœ… ë””ë ‰í† ë¦¬ ì‚­ì œ ì™„ë£Œ")
                    except Exception as e:
                        print(f"âš ï¸ ë””ë ‰í† ë¦¬ ì‚­ì œ ì‹¤íŒ¨: {e}")
                        # ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
                
                # 3. ë””ë ‰í† ë¦¬ ë‹¤ì‹œ ìƒì„±
                self.persist_directory.mkdir(parents=True, exist_ok=True)
                print("ğŸ“ ìƒˆë¡œìš´ ë””ë ‰í† ë¦¬ ìƒì„± ì™„ë£Œ")
                
                # 4. ì ì‹œ ëŒ€ê¸° (íŒŒì¼ ì‹œìŠ¤í…œ ì•ˆì •í™”)
                print("â³ íŒŒì¼ ì‹œìŠ¤í…œ ì•ˆì •í™” ëŒ€ê¸°...")
                time.sleep(2)
                
                # 5. ì™„ì „íˆ ìƒˆë¡œìš´ ë²¡í„° ì €ì¥ì†Œ ìƒì„±
                collection_name = "school_notices"
                
                print(f"ğŸ”§ ìƒˆ Chroma ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì¤‘... (ì»¬ë ‰ì…˜: {collection_name})")
                
                self.vector_store = Chroma.from_documents(
                    documents=documents,
                    embedding=self.embeddings,
                    persist_directory=str(self.persist_directory),
                    collection_name=collection_name
                )
                
                print(f"âœ… Chroma ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì™„ë£Œ: {self.persist_directory}")
                
                # 6. ìƒì„± í›„ ë¬¸ì„œ ê°œìˆ˜ í™•ì¸
                try:
                    if hasattr(self.vector_store, '_collection'):
                        count = self.vector_store._collection.count()
                        print(f"ğŸ“Š ì €ì¥ëœ ë¬¸ì„œ ê°œìˆ˜: {count}")
                    
                    # ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
                    test_results = self.vector_store.similarity_search("í…ŒìŠ¤íŠ¸", k=1)
                    print(f"ğŸ“Š ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ê²°ê³¼: {len(test_results)}ê°œ ë¬¸ì„œ ë°˜í™˜")
                    
                except Exception as e:
                    print(f"âš ï¸ ë¬¸ì„œ ê°œìˆ˜ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
                    
            elif self.vector_db_type == "faiss":
                # FAISS ë²¡í„° ì €ì¥ì†Œ ìƒì„±
                print("ğŸ”§ FAISS ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì¤‘...")
                
                # ê¸°ì¡´ FAISS íŒŒì¼ë“¤ ì‚­ì œ
                faiss_path = self.persist_directory / "faiss_index"
                if faiss_path.exists():
                    import shutil
                    shutil.rmtree(str(faiss_path))
                    print(f"ğŸ—‘ï¸ ê¸°ì¡´ FAISS ì¸ë±ìŠ¤ ì‚­ì œ: {faiss_path}")
                
                self.vector_store = FAISS.from_documents(
                    documents=documents,
                    embedding=self.embeddings
                )
                
                # FAISS ì¸ë±ìŠ¤ ì €ì¥
                faiss_path.mkdir(parents=True, exist_ok=True)
                self.vector_store.save_local(str(faiss_path))
                print(f"âœ… FAISS ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì™„ë£Œ: {faiss_path}")
                
            else:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ë²¡í„° DBì…ë‹ˆë‹¤: {self.vector_db_type}")
                
        except Exception as e:
            print(f"âŒ ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
            
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ëŒ€ì•ˆ ë°©ë²• ì‹œë„
            print("ğŸ”„ ëŒ€ì•ˆ ë°©ë²•ìœ¼ë¡œ ì¬ì‹œë„...")
            self._try_alternative_creation(documents)
    
    def _try_alternative_creation(self, documents: List[Document]):
        """
        ëŒ€ì•ˆ ë°©ë²•ìœ¼ë¡œ ë²¡í„° ì €ì¥ì†Œ ìƒì„±
        """
        try:
            # ì„ì‹œ ë””ë ‰í† ë¦¬ ì‚¬ìš©
            import tempfile
            temp_dir = Path(tempfile.mkdtemp(prefix="chroma_temp_"))
            print(f"ğŸ”„ ì„ì‹œ ë””ë ‰í† ë¦¬ ì‚¬ìš©: {temp_dir}")
            
            # ì„ì‹œ ë””ë ‰í† ë¦¬ì— ë²¡í„° ì €ì¥ì†Œ ìƒì„±
            temp_store = Chroma.from_documents(
                documents=documents,
                embedding=self.embeddings,
                persist_directory=str(temp_dir),
                collection_name="temp_collection"
            )
            
            print("âœ… ì„ì‹œ ìœ„ì¹˜ì— ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì„±ê³µ")
            
            # ì„±ê³µí•˜ë©´ ì›ë˜ ìœ„ì¹˜ë¡œ ì´ë™ ì‹œë„
            import shutil
            if self.persist_directory.exists():
                # ê¸°ì¡´ ë””ë ‰í† ë¦¬ ë°±ì—…
                backup_dir = self.persist_directory.parent / f"vector_db_backup_{int(time.time())}"
                shutil.move(str(self.persist_directory), str(backup_dir))
                print(f"ğŸ“‹ ê¸°ì¡´ ë””ë ‰í† ë¦¬ ë°±ì—…: {backup_dir}")
            
            # ì„ì‹œ ë””ë ‰í† ë¦¬ë¥¼ ì›ë˜ ìœ„ì¹˜ë¡œ ì´ë™
            shutil.move(str(temp_dir), str(self.persist_directory))
            print(f"ğŸ“ ë²¡í„° ì €ì¥ì†Œë¥¼ ì›ë˜ ìœ„ì¹˜ë¡œ ì´ë™: {self.persist_directory}")
            
            # ìƒˆë¡œìš´ ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ
            self.vector_store = Chroma(
                persist_directory=str(self.persist_directory),
                embedding_function=self.embeddings,
                collection_name="temp_collection"
            )
            
            print("âœ… ëŒ€ì•ˆ ë°©ë²•ìœ¼ë¡œ ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ ëŒ€ì•ˆ ë°©ë²•ë„ ì‹¤íŒ¨: {e}")
    
    def similarity_search(self, 
                         query: str, 
                         k: int = 4, 
                         filter_dict: Optional[Dict] = None) -> List[Document]:
        """
        ìœ ì‚¬ë„ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜
        
        Args:
            query (str): ê²€ìƒ‰ ì¿¼ë¦¬
            k (int): ë°˜í™˜í•  ë¬¸ì„œ ê°œìˆ˜
            filter_dict (Optional[Dict]): ë©”íƒ€ë°ì´í„° í•„í„°
            
        Returns:
            List[Document]: ê²€ìƒ‰ ê²°ê³¼ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        """
        if not self.vector_store:
            print("âŒ ë²¡í„° ì €ì¥ì†Œê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return []
            
        try:
            print(f"ğŸ” ê²€ìƒ‰ ì¤‘: '{query}' (k={k})")
            
            if filter_dict and self.vector_db_type == "chroma":
                # ChromaëŠ” ë©”íƒ€ë°ì´í„° í•„í„°ë§ ì§€ì›
                results = self.vector_store.similarity_search(
                    query=query,
                    k=k,
                    filter=filter_dict
                )
            else:
                # ê¸°ë³¸ ìœ ì‚¬ë„ ê²€ìƒ‰
                results = self.vector_store.similarity_search(
                    query=query,
                    k=k
                )
            
            print(f"ğŸ“Š ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ ë¬¸ì„œ ë°œê²¬")
            return results
            
        except Exception as e:
            print(f"âŒ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return []
    
    def similarity_search_with_score(self, 
                                   query: str, 
                                   k: int = 4) -> List[tuple]:
        """
        ìœ ì‚¬ë„ ì ìˆ˜ì™€ í•¨ê»˜ ê²€ìƒ‰í•˜ëŠ” í•¨ìˆ˜
        
        Args:
            query (str): ê²€ìƒ‰ ì¿¼ë¦¬
            k (int): ë°˜í™˜í•  ë¬¸ì„œ ê°œìˆ˜
            
        Returns:
            List[tuple]: (Document, score) íŠœí”Œ ë¦¬ìŠ¤íŠ¸
        """
        if not self.vector_store:
            print("âŒ ë²¡í„° ì €ì¥ì†Œê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return []
            
        try:
            print(f"ğŸ” ì ìˆ˜ í¬í•¨ ê²€ìƒ‰ ì¤‘: '{query}' (k={k})")
            
            results = self.vector_store.similarity_search_with_score(
                query=query,
                k=k
            )
            
            print(f"ğŸ“Š ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ ë¬¸ì„œ ë°œê²¬")
            return results
            
        except Exception as e:
            print(f"âŒ ì ìˆ˜ í¬í•¨ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return []
    
    def test_search(self, test_queries: List[str]) -> None:
        """
        í…ŒìŠ¤íŠ¸ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜
        
        Args:
            test_queries (List[str]): í…ŒìŠ¤íŠ¸í•  ì¿¼ë¦¬ ë¦¬ìŠ¤íŠ¸
        """
        if not self.vector_store:
            print("âŒ ë²¡í„° ì €ì¥ì†Œê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return
            
        print("\n=== ğŸ” ë²¡í„° ì €ì¥ì†Œ í…ŒìŠ¤íŠ¸ ê²€ìƒ‰ ===")
        
        for i, query in enumerate(test_queries, 1):
            print(f"\n--- í…ŒìŠ¤íŠ¸ {i}: '{query}' ---")
            
            try:
                # ìœ ì‚¬ë„ ê²€ìƒ‰ (ì ìˆ˜ í¬í•¨)
                results = self.similarity_search_with_score(query, k=3)
                
                if results:
                    for j, (doc, score) in enumerate(results, 1):
                        print(f"  {j}. [ì ìˆ˜: {score:.4f}] {doc.metadata.get('title', 'N/A')}")
                        print(f"     ì¹´í…Œê³ ë¦¬: {doc.metadata.get('category', 'N/A')}")
                        print(f"     ë‚´ìš©: {doc.page_content[:100]}...")
                        print()
                else:
                    print("  âŒ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    
            except Exception as e:
                print(f"  âŒ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
    
    def get_vector_store_info(self) -> Dict[str, Any]:
        """
        ë²¡í„° ì €ì¥ì†Œ ì •ë³´ë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
        
        Returns:
            Dict: ë²¡í„° ì €ì¥ì†Œ ì •ë³´
        """
        info = {
            "embedding_model": self.embedding_model_type,
            "vector_db_type": self.vector_db_type,
            "persist_directory": str(self.persist_directory),
            "is_initialized": self.vector_store is not None,
            "timestamp": datetime.now().isoformat()
        }
        
        if self.vector_store and self.vector_db_type == "chroma":
            try:
                if hasattr(self.vector_store, '_collection'):
                    collection = self.vector_store._collection
                    info["document_count"] = collection.count()
                else:
                    test_results = self.vector_store.similarity_search("í…ŒìŠ¤íŠ¸", k=1)
                    info["document_count"] = "ê²€ìƒ‰ ê°€ëŠ¥" if test_results else "ë¹„ì–´ìˆìŒ"
            except Exception as e:
                info["document_count"] = f"í™•ì¸ ë¶ˆê°€: {e}"
        
        return info


def main():
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ - ì•ˆì „í•œ ë²¡í„° ì €ì¥ì†Œ êµ¬ì¶•
    """
    print("=== ğŸš€ ì•ˆì „í•œ ë²¡í„° ì €ì¥ì†Œ êµ¬ì¶• ì‹œì‘ ===")
    print(f"ğŸ“ í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬: {Path.cwd()}")
    print(f"ğŸ“ í”„ë¡œì íŠ¸ ë£¨íŠ¸: {PROJECT_ROOT}")
    
    # 1. ë¬¸ì„œ ì²˜ë¦¬ê¸°ë¡œ ë¬¸ì„œ ë¡œë“œ ë° ì²˜ë¦¬
    print("\n1. ğŸ“„ ë¬¸ì„œ ì²˜ë¦¬ ì¤‘...")
    
    processor = DocumentProcessor(data_directory=str(PROJECT_ROOT / "data" / "raw"))
    chunks = processor.process_documents()
    
    if not chunks:
        print("âŒ ì²˜ë¦¬ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
        print("ğŸ”§ í•´ê²° ë°©ë²•:")
        print(f"   1. {PROJECT_ROOT / 'data' / 'raw'} ë””ë ‰í† ë¦¬ì— .txt íŒŒì¼ë“¤ì„ ë„£ì–´ì£¼ì„¸ìš”")
        print(f"   2. {PROJECT_ROOT / 'data' / 'raw' / 'metadata.json'} íŒŒì¼ì„ ìƒì„±í•´ì£¼ì„¸ìš”")
        return
    
    print(f"âœ… ì²˜ë¦¬ëœ ì²­í¬ ìˆ˜: {len(chunks)}")
    
    # 2. ì•ˆì „í•œ ë²¡í„° ì €ì¥ì†Œ ê´€ë¦¬ì ì´ˆê¸°í™”
    print("\n2. ğŸ”§ ì•ˆì „í•œ ë²¡í„° ì €ì¥ì†Œ ê´€ë¦¬ì ì´ˆê¸°í™” ì¤‘...")
    vector_manager = SafeVectorStoreManager(
        embedding_model="korean",  # í•œêµ­ì–´ íŠ¹í™” ëª¨ë¸ ì‚¬ìš©
        vector_db_type="chroma",   # Chroma DB ì‚¬ìš©
        persist_directory=None     # ê¸°ë³¸ê°’: PROJECT_ROOT/data/vector_db
    )
    
    # 3. ì•ˆì „í•œ ë²¡í„° ì €ì¥ì†Œ ìƒì„±
    print("\n3. ğŸ—ï¸ ì•ˆì „í•œ ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì¤‘...")
    vector_manager.create_vector_store_safe(chunks)
    
    # 4. ë²¡í„° ì €ì¥ì†Œ ì •ë³´ ì¶œë ¥
    if vector_manager.vector_store:
        print("\n4. ğŸ“Š ë²¡í„° ì €ì¥ì†Œ ì •ë³´:")
        info = vector_manager.get_vector_store_info()
        for key, value in info.items():
            print(f"   {key}: {value}")
        
        # 5. í…ŒìŠ¤íŠ¸ ê²€ìƒ‰ ìˆ˜í–‰
        test_queries = [
            "ì¥í•™ê¸ˆ ì‹ ì²­ ë°©ë²•",
            "ë„ì„œê´€ ìš´ì˜ì‹œê°„", 
            "í•´ì™¸êµí™˜í•™ìƒ í”„ë¡œê·¸ë¨",
            "ì·¨ì—…ë°•ëŒíšŒ ì¼ì •",
            "í•™ìƒì‹ë‹¹ ë©”ë‰´"
        ]
        
        vector_manager.test_search(test_queries)
        
        print("\n=== ğŸ‰ ì•ˆì „í•œ ë²¡í„° ì €ì¥ì†Œ êµ¬ì¶• ì™„ë£Œ ===")
        print(f"ğŸ“ ë²¡í„° DB ì €ì¥ ìœ„ì¹˜: {vector_manager.persist_directory}")
    else:
        print("\nâŒ ë²¡í„° ì €ì¥ì†Œ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    main()